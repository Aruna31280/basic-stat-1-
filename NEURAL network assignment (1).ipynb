{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ee86b-3f1e-4a29-97d2-fec6f6e00fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                               ARTIFICIAL NEURAL NETWORKS ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eaa8f11-f135-4c8d-9cbe-04b19400e6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          T     2     8      3       5      1     8    13      0      6   \n",
       "1          I     5    12      3       7      2    10     5      5      4   \n",
       "2          D     4    11      6       8      6    10     6      2      6   \n",
       "3          N     7    11      6       6      3     5     9      4      6   \n",
       "4          G     2     1      3       1      1     8     6      6      6   \n",
       "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19995      D     2     2      3       3      2     7     7      7      6   \n",
       "19996      C     7    10      8       8      4     4     8      6      9   \n",
       "19997      T     6     9      6       7      5     6    11      3      7   \n",
       "19998      S     2     3      4       2      1     8     7      2      6   \n",
       "19999      A     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "df = pd.read_csv(\"Alphabets_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0169838b-b3f7-44f1-a7ae-3dba8639b4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  xybar  \\\n",
      "0      T     2     8      3       5      1     8    13      0      6      6   \n",
      "1      I     5    12      3       7      2    10     5      5      4     13   \n",
      "2      D     4    11      6       8      6    10     6      2      6     10   \n",
      "3      N     7    11      6       6      3     5     9      4      6      4   \n",
      "4      G     2     1      3       1      1     8     6      6      6      6   \n",
      "\n",
      "   x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
      "0      10       8      0       8      0       8  \n",
      "1       3       9      2       8      4      10  \n",
      "2       3       7      3       7      3       9  \n",
      "3       4      10      6      10      2       8  \n",
      "4       5       9      1       7      5      10  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8013fb48-00b6-4f6f-b09f-20400b12bca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 17)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2f42310-699f-4c7a-b271-b293afd9c50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['letter', 'xbox', 'ybox', 'width', 'height', 'onpix', 'xbar', 'ybar',\n",
      "       'x2bar', 'y2bar', 'xybar', 'x2ybar', 'xy2bar', 'xedge', 'xedgey',\n",
      "       'yedge', 'yedgex'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b9bf459-5968-496f-bd38-f80189dd6369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of       letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
      "0          T     2     8      3       5      1     8    13      0      6   \n",
      "1          I     5    12      3       7      2    10     5      5      4   \n",
      "2          D     4    11      6       8      6    10     6      2      6   \n",
      "3          N     7    11      6       6      3     5     9      4      6   \n",
      "4          G     2     1      3       1      1     8     6      6      6   \n",
      "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
      "19995      D     2     2      3       3      2     7     7      7      6   \n",
      "19996      C     7    10      8       8      4     4     8      6      9   \n",
      "19997      T     6     9      6       7      5     6    11      3      7   \n",
      "19998      S     2     3      4       2      1     8     7      2      6   \n",
      "19999      A     4     9      6       6      2     9     5      3      1   \n",
      "\n",
      "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
      "0          6      10       8      0       8      0       8  \n",
      "1         13       3       9      2       8      4      10  \n",
      "2         10       3       7      3       7      3       9  \n",
      "3          4       4      10      6      10      2       8  \n",
      "4          6       5       9      1       7      5      10  \n",
      "...      ...     ...     ...    ...     ...    ...     ...  \n",
      "19995      6       6       4      2       8      3       7  \n",
      "19996     12       9      13      2       9      3       7  \n",
      "19997     11       9       5      2      12      2       4  \n",
      "19998     10       6       8      1       9      5       8  \n",
      "19999      8       1       8      2       7      2       8  \n",
      "\n",
      "[20000 rows x 17 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "043e1e0f-ebd9-4453-ae32-1717118aa2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter    0\n",
      "xbox      0\n",
      "ybox      0\n",
      "width     0\n",
      "height    0\n",
      "onpix     0\n",
      "xbar      0\n",
      "ybar      0\n",
      "x2bar     0\n",
      "y2bar     0\n",
      "xybar     0\n",
      "x2ybar    0\n",
      "xy2bar    0\n",
      "xedge     0\n",
      "xedgey    0\n",
      "yedge     0\n",
      "yedgex    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0f34487-da05-4e74-bde7-1c2144e52834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 26\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Alphabets_data.csv\")\n",
    "print(\"Number of classes:\", df['letter'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24dea27c-9f94-43c5-94ea-516ee16cd4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: (16000, 16)\n",
      "Test set size: (4000, 16)\n"
     ]
    }
   ],
   "source": [
    "#data processing\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Alphabets_data.csv\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop('letter', axis=1)   \n",
    "y = df['letter']                \n",
    "\n",
    "# Encode labels (if categorical text)\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "y = to_categorical(y) \n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"\\nTraining set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d7a4938-2482-4ad1-92c9-c8ee53b8c1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ridhv\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.4234 - loss: 0.8251 - val_accuracy: 0.5000 - val_loss: 0.7999\n",
      "Epoch 2/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4891 - loss: 0.7564 - val_accuracy: 0.5375 - val_loss: 0.7388\n",
      "Epoch 3/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5437 - loss: 0.7020 - val_accuracy: 0.5625 - val_loss: 0.6891\n",
      "Epoch 4/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6062 - loss: 0.6569 - val_accuracy: 0.6062 - val_loss: 0.6469\n",
      "Epoch 5/5\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6609 - loss: 0.6185 - val_accuracy: 0.6438 - val_loss: 0.6119\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6250 - loss: 0.6264 \n",
      "Test Accuracy: 62.50%\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Predictions: [0 0 0 0 0 1 0 0 0 0]\n",
      "Actual labels: [0 1 1 1 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# model implementation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "df = pd.read_csv(\"Alphabets_data.csv\")\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "\n",
    "#  Split dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)\n",
    "\n",
    "# ANN Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#  Compile the Model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#  Train the Model\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "#  Evaluate Model \n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "y_pred_prob = model.predict(X_test)  # Probabilities\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to 0 or 1\n",
    "\n",
    "#  Show first 10 predictions vs actual labels\n",
    "print(\"Predictions:\", y_pred[:10].flatten())\n",
    "print(\"Actual labels:\", y_test[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc5a5131-fe84-4bb0-9223-49e8343d974f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasClassifier(\n",
      "\tmodel=<function create_model at 0x0000016EBBC95B20>\n",
      "\tbuild_fn=None\n",
      "\twarm_start=False\n",
      "\trandom_state=None\n",
      "\toptimizer=rmsprop\n",
      "\tloss=None\n",
      "\tmetrics=None\n",
      "\tbatch_size=8\n",
      "\tvalidation_batch_size=None\n",
      "\tverbose=0\n",
      "\tcallbacks=None\n",
      "\tvalidation_split=0.0\n",
      "\tshuffle=True\n",
      "\trun_eagerly=False\n",
      "\tepochs=5\n",
      "\tclass_weight=None\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "clf = KerasClassifier(model=create_model, epochs=5, batch_size=8, verbose=0)\n",
    "print(clf)  # should print a scikeras wrapper object, no AttributeError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88385e72-75c0-4563-b990-2d3fd11cdf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ridhv\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross-Validation Score: 0.8638\n",
      "Best Hyperparameters: {'batch_size': 16, 'epochs': 20, 'model__activation': 'tanh', 'model__hidden_layers': 1, 'model__learning_rate': 0.001, 'model__neurons': 32}\n",
      "Test set accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter tuning\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20,\n",
    "                           n_classes=2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "    #Build ANN model \n",
    "def create_model(hidden_layers=1, neurons=16, activation='relu', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    # first hidden layer\n",
    "    model.add(Dense(neurons, activation=activation, input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    # Additional hidden layers \n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    \n",
    "    # Output layer \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#  Wrap with SciKeras \n",
    "clf = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "\n",
    "                      #hyperparameter grid\n",
    "param_grid = {\n",
    "    \"model__hidden_layers\": [1, 2],       \n",
    "    \"model__neurons\": [16, 32],           \n",
    "    \"model__activation\": [\"relu\", \"tanh\"],\n",
    "    \"model__learning_rate\": [0.001, 0.01],\n",
    "    \"batch_size\": [16, 32],               \n",
    "    \"epochs\": [20]                        \n",
    "}\n",
    "#  Grid Search \n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid,\n",
    "                    cv=3, n_jobs=-1, scoring=\"accuracy\")\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Cross-Validation Score: %.4f\" % grid_result.best_score_)\n",
    "print(\"Best Hyperparameters:\", grid_result.best_params_)\n",
    "print(\"Test set accuracy:\", grid.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7321a78-0b60-4672-b000-bc38311fe2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ridhv\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "🔹 Default Model Performance\n",
      "Accuracy: 0.835\n",
      "Precision (macro): 0.838317944600562\n",
      "Recall (macro): 0.8387599236257662\n",
      "F1-score (macro): 0.8349958748968724\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83        93\n",
      "           1       0.89      0.79      0.84       107\n",
      "\n",
      "    accuracy                           0.83       200\n",
      "   macro avg       0.84      0.84      0.83       200\n",
      "weighted avg       0.84      0.83      0.84       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[83 10]\n",
      " [23 84]]\n",
      "\n",
      "🔹 Tuned Model Performance\n",
      "Accuracy: 0.875\n",
      "Precision (macro): 0.8758503401360545\n",
      "Recall (macro): 0.8775499949753793\n",
      "F1-score (macro): 0.8749218261413383\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87        93\n",
      "           1       0.92      0.84      0.88       107\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.88      0.88      0.87       200\n",
      "weighted avg       0.88      0.88      0.88       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[85  8]\n",
      " [17 90]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "#  Default Model \n",
    "default_model = create_model()\n",
    "default_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "y_pred_default = (default_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(\"🔹 Default Model Performance\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_default))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred_default, average=\"macro\"))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_default, average=\"macro\"))\n",
    "print(\"F1-score (macro):\", f1_score(y_test, y_pred_default, average=\"macro\"))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_default))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_default))\n",
    "\n",
    "#  Evaluate Tuned Mod\n",
    "best_model = grid_result.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n🔹 Tuned Model Performance\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tuned))\n",
    "print(\"Precision (macro):\", precision_score(y_test, y_pred_tuned, average=\"macro\"))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_tuned, average=\"macro\"))\n",
    "print(\"F1-score (macro):\", f1_score(y_test, y_pred_tuned, average=\"macro\"))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_tuned))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tuned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c2ab8c-dc9d-4593-9c12-7e7ba4ff3c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ridhv\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ridhv\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Performance Comparison\n",
      "           Default Model  Tuned Model\n",
      "Accuracy        0.845000     0.850000\n",
      "Precision       0.904255     0.888889\n",
      "Recall          0.794393     0.822430\n",
      "F1-score        0.845771     0.854369\n",
      "\n",
      "Classification Report (Default Model):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84        93\n",
      "           1       0.90      0.79      0.85       107\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.85      0.85      0.84       200\n",
      "weighted avg       0.85      0.84      0.85       200\n",
      "\n",
      "Confusion Matrix (Default Model):\n",
      " [[84  9]\n",
      " [22 85]]\n",
      "\n",
      "Classification Report (Tuned Model):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85        93\n",
      "           1       0.89      0.82      0.85       107\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.85      0.85      0.85       200\n",
      "weighted avg       0.85      0.85      0.85       200\n",
      "\n",
      "Confusion Matrix (Tuned Model):\n",
      " [[82 11]\n",
      " [19 88]]\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20,\n",
    "                           n_classes=2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "    #ANN model builder \n",
    "def create_model(hidden_layers=1, neurons=16, activation='relu', learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=activation, input_shape=(X_train.shape[1],)))\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#  Default ANN model \n",
    "default_model = create_model()\n",
    "default_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "y_pred_default = (default_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "#  Hyperparameter tuning with GridSearch \n",
    "clf = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    \"model__hidden_layers\": [1, 2],\n",
    "    \"model__neurons\": [16, 32],\n",
    "    \"model__activation\": [\"relu\", \"tanh\"],\n",
    "    \"model__learning_rate\": [0.001, 0.01],\n",
    "    \"batch_size\": [16, 32],\n",
    "    \"epochs\": [20]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=clf, param_grid=param_grid,\n",
    "                    cv=3, n_jobs=-1, scoring=\"accuracy\")\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "best_model = grid_result.best_estimator_\n",
    "y_pred_tuned = best_model.predict(X_test)\n",
    "\n",
    "#  Evaluation\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred),\n",
    "        \"Recall\": recall_score(y_true, y_pred),\n",
    "        \"F1-score\": f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Default Model\": evaluate_model(y_test, y_pred_default),\n",
    "    \"Tuned Model\": evaluate_model(y_test, y_pred_tuned)\n",
    "})\n",
    "\n",
    "print(\"\\n🔹 Performance Comparison\")\n",
    "print(results)\n",
    "\n",
    "print(\"\\nClassification Report (Default Model):\\n\", classification_report(y_test, y_pred_default))\n",
    "print(\"Confusion Matrix (Default Model):\\n\", confusion_matrix(y_test, y_pred_default))\n",
    "\n",
    "print(\"\\nClassification Report (Tuned Model):\\n\", classification_report(y_test, y_pred_tuned))\n",
    "print(\"Confusion Matrix (Tuned Model):\\n\", confusion_matrix(y_test, y_pred_tuned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797a6c1-34bf-4804-a18c-f96e326c1d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation criteria\n",
    "1. Accuracy & Completeness of Implementation :Code runs & implements ANN from scratch with Keras/TensorFlow, includes at least one\n",
    "hidden layer, trains & evaluates properly. All required tasks  are implemented fully.\n",
    "\n",
    "2. Proficiency in Data Preprocessing & Model Development :Dataset cleaned, features standardized/normalized Train/test split done correctly.\n",
    "ANN model designed logicically.\n",
    "    \n",
    "3. Systematic Approach & Thoroughness in Hyperparameter Tuning: Clear methodology of GridSearchCV ,Multiple  number of layers, neurons,\n",
    "activation, learning rate, batch size, epochs.\n",
    "\n",
    "4. Depth of Evaluation & Discussion : Evaluation includes accuracy, precision, recall, F1, confusion matrix\n",
    "\n",
    "5. Overall Quality of Report : Report is clear, well-structured, professional. Includes results, and discussion.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
